{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinRes\n",
    "We are studing  the paper [Solution of Sparse Indefinite Systems of Linear Equations](#paige1975) and correlated articles.    The following text is partly or completely taken from this article and the references at the end.\n",
    "\n",
    "All presented algorithms and examples are implemented in Python.\n",
    "\n",
    "We want to solve\n",
    "$Ax=b$, where $A\\in\\mathbb{R}^{N\\times N}$ is nonsingular and symmetric, but indefinite.   \n",
    "\n",
    "First we present the Lanczos tridiagonalization method\n",
    "\n",
    "## Lanczos method\n",
    "\n",
    "In [Meurant,2006](#meurant2006) we read:\n",
    "\n",
    "*This numerical method was introduced by Cornelius Lanczos (see the biographical notes\n",
    "in the appendix) in 1950 [108]. We should mention in passing that this paper is still worth\n",
    "reading more than half a century later. The algorithm was intended to compute the coefficients of the characteristic polynomial of a matrix as a mean to compute the eigenvalues of\n",
    "a symmetric matrix as it was common in those days. The Lanczos algorithm is a projection\n",
    "method on a Krylov subspace [106]. The Krylov subspace $\\mathcal{K}_k(v, A)$ of order $k$ based on the\n",
    "vector $v$ and the matrix $A$ of order $n$ is $\\operatorname{span}\\{v, Av,..., A^{k-1} v\\}$. Lanczos first introduced\n",
    "a method using these basis vectors. He noticed that, even though this was an improvement\n",
    "over previous methods, this can lead to very severe coefficient growth problems when the\n",
    "condition number of the matrix is large (by 1950 standards). This led him to propose a\n",
    "method he called \"minimized iterations,\" which is what we now call the Lanczos algorithm\n",
    "(although he used a different normalization). This method computed an orthogonal basis of\n",
    "the Krylov subspace. Lanczos in a footnote attributed the successive orthogonalization of\n",
    "a set of vectors to O. Szaz (1910), a Hungarian mathematician. However, this process that\n",
    "we now call the Gram-Schmidt algorithm was introduced for sets of functions by J.P. Gram\n",
    "(1883) and E. Schmidt (1907), although there is a mostly unnoticed result of Laplace on this\n",
    "subject (1820) and this was also essentially used by Cauchy in 1836. According to Stewart\n",
    "[178] it was used by G. Kowalevski for finite dimensional spaces in 1909. Actually, in his\n",
    "1950 paper Lanczos also introduced the nonsymmetric Lanczos method for nonsymmetric\n",
    "matrices using two sets of biorthogonal vectors defined with the help of AT. He noticed the\n",
    "connection of his method with orthogonal polynomials and the problems of rounding errors,\n",
    "mentioning that the problem can be solved by full reorthogonalization of the computed basis\n",
    "vectors.*\n",
    "\n",
    "\n",
    "Here's a brief overview of the Lanczos algorithm:\n",
    "\n",
    "1. **Initialization:** Choose a starting vector $ v_1 $ (usually a random vector or a vector with predetermined properties) and normalize it.\n",
    "\n",
    "2. **Iterative Process:** Generate a sequence of vectors $ v_2, \\ldots, v_k $ by iteratively applying the Lanczos iteration:\n",
    "   - a. Compute $ Av_k $ (where $ A $ is the original symmetric matrix).\n",
    "   - b. Apply the Gram-Schmidt process to orthogonalize $ Av_k $ against $ v_k$.\n",
    "   - c. Compute the coefficients $ \\alpha_k $ and $ \\beta_k $ such that $ Av_k = \\alpha_k v_k + \\beta_{k-1} v_{k-1} $ and $ \\beta_k = ||Av_k|| $.\n",
    "\n",
    "3. **Tridiagonalization:** After a certain number of iterations or when desired accuracy is achieved, construct the tridiagonal matrix $ T $ using the coefficients $ \\alpha_k $ and $ \\beta_k $.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues of A: [-3.59177388 -2.64526309 -2.32346079 -2.14766597 -1.53915027 -1.38613407\n",
      " -1.02971191 -0.76873155 -0.3432294  -0.0588308   0.08121816  0.66895751\n",
      "  1.00701243  1.27577577  1.87772681  1.92455528  2.26161105  2.7377746\n",
      "  3.51376098 19.36154309]\n",
      "Eigenvalues of T: [-3.17068519 -0.54257183  2.02587461 19.36153727]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def lanczos_algorithm(matrix, vector, max_iterations=100, kry=10):\n",
    "    # version of Meurant's book, p. 8\n",
    "    \n",
    "    # Initialize variables\n",
    "    [m, n]=matrix.shape\n",
    "    maxiter=min(m,max_iterations)\n",
    "    alpha = np.zeros(maxiter)\n",
    "    beta = np.zeros(maxiter)\n",
    "    v = np.zeros([maxiter+1,n])\n",
    "    u = np.zeros(n)\n",
    "\n",
    "    v[0]= np.copy(vector)  \n",
    "    v[0]=v[0]/np.linalg.norm(v[0]) # normalize the initial vector\n",
    "    v[1]=np.dot(matrix, v[0]) # v1=A*v0\n",
    "    alpha[0]=np.dot(v[1],v[0]) # size of the projection of v1 onto v0\n",
    "    v[1]=v[1]-alpha[0]*v[0] # computes the orthogonal component of v1 wrt v0\n",
    "    # Lanczos iteration\n",
    "\n",
    "    for k in range(1,maxiter):\n",
    "        beta[k-1]=np.linalg.norm(v[k])\n",
    "        if beta[k-1] == 0:\n",
    "            break \n",
    "        v[k]=v[k]/beta[k-1]\n",
    "        u=np.dot(matrix, v[k])-beta[k-1]*v[k-1]\n",
    "        alpha[k]=np.dot(v[k],u)\n",
    "        v[k+1]=u-alpha[k]*v[k]\n",
    "\n",
    "    # Tridiagonal matrix construction\n",
    "    T = np.diag(alpha) + np.diag(beta[:-1], 1) + np.diag(beta[:-1], -1)\n",
    "    \n",
    "    return T, v\n",
    "\n",
    "n=20\n",
    "kry=4\n",
    "A=  np.random.rand(n,n)\n",
    "A= A+np.transpose(A)\n",
    "#print('A= ', A)\n",
    "\n",
    "# Define an initial vector\n",
    "v0 = np.random.rand(n)\n",
    "\n",
    "# Apply Lanczos algorithm\n",
    "tridiagonal_matrix, lanc_vec = lanczos_algorithm(A, v0, kry)\n",
    "\n",
    "#print(\"Tridiagonal matrix:\")\n",
    "#print(tridiagonal_matrix)\n",
    "\n",
    "np.set_printoptions(precision=8)\n",
    "eigenvaluesA, eigenvectorsA = np.linalg.eig(A)\n",
    "print(\"Eigenvalues of A:\", np.sort(eigenvaluesA))\n",
    "#print(\"Eigenvectors of A:\", eigenvectorsA)\n",
    "eigenvaluesT, eigenvectorsT = np.linalg.eig(tridiagonal_matrix)\n",
    "print(\"Eigenvalues of T:\", np.sort(eigenvaluesT))\n",
    "#print(\"Eigenvectors of T:\", eigenvectorsT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    " - *Meurant, GÃ©rard*, \"The Lanczos and conjugate gradient algorithms : from theory to finite precision computations\", SIAM, 2006. <a name=\"meurant2006\"></a>\n",
    " - *Paige, Christopher C., and Michael A. Saunders*, \"Solution of sparse indefinite systems of linear equations\", SIAM Journal on Numerical Analysis 12.4 (1975): 617-629.  https://doi.org/10.1137/0712047 <a name=\"paige1975\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
