{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPcsKhzDLtiKE3kR9UJaYcb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Krylov methods CG and GMRES\n","\n","We study the paper [Towards understanding CG and GMRES through\n","examples](#cls2024).    The following text is partly or completely taken from this article.\n","\n","All presented algorithms and examples are implemented in Python.\n","\n","We want to solve\n","$Ax=b$, where $A\\in\\mathbb{R}^{N\\times N}$ is nonsingular.  "],"metadata":{"id":"Bi_BhDS8-xnE"}},{"cell_type":"markdown","source":["## CG Python implementation"],"metadata":{"id":"SZXk73sL2sNb"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-z-PH18XqXPf","executionInfo":{"status":"ok","timestamp":1714150719841,"user_tz":180,"elapsed":406,"user":{"displayName":"Luiz M. Carvalho","userId":"03500398417100793324"}},"outputId":"70c9b6a0-e2ec-4bfe-dd60-5e8f10109403"},"outputs":[{"output_type":"stream","name":"stdout","text":["CG solution: [ 1.65853659 -0.36585366  0.87804878]\n","Number of iterations: 3\n","Exact solution: [ 1.65853659 -0.36585366  0.87804878]\n","Solution relative error: 8.710125287018885e-17\n"]}],"source":["import numpy as np\n","\n","def cg_cls(A, b, x0, sol, tol=1e-6, max_iter=1000):\n","    \"\"\"\n","    Solve the linear system Ax = b using the conjugate gradient method.\n","\n","    Parameters:\n","        A (numpy.ndarray): The coefficient matrix of the linear system.\n","        b (numpy.ndarray): The right-hand side vector.\n","        x0 (numpy.ndarray): The initial guess for the solution.\n","        sol (numpy.ndarray): The actual  solution.\n","        tol (float): The tolerance for convergence.\n","        max_iter (int): The maximum number of iterations allowed.\n","\n","    Returns:\n","        x (numpy.ndarray): The solution vector.\n","        num_iterations (int): The number of iterations performed.\n","    \"\"\"\n","    r = b - np.dot(A, x0)\n","    p = r\n","    x = x0\n","    r_dot_old = np.dot(r, r)\n","\n","    for k in range(max_iter):\n","        Ap = np.dot(A, p)\n","        alpha = r_dot_old / np.dot(p, Ap)\n","        x = x + alpha * p\n","        r = r - alpha * Ap\n","        r_dot_new = np.dot(r, r)\n","        if np.sqrt(r_dot_new) < tol:\n","            break\n","        beta = r_dot_new / r_dot_old\n","        p = r + beta * p\n","        r_dot_old = r_dot_new\n","\n","\n","    num_iterations = k + 1\n","    return x, num_iterations\n","\n","# Example usage:\n","A = np.array([[4, -1, 0], [-1, 4, -1], [0, -1, 3]])\n","b = np.array([7, -4, 3])\n","sol = np.linalg.solve(A,b)\n","x0 = np.zeros_like(b)\n","appsol, num_iterations = cg_cls(A, b, x0, sol)\n","print(\"CG solution:\", appsol)\n","print(\"Number of iterations:\", num_iterations)\n","print(\"Exact solution:\",sol)\n","print(\"Solution relative error:\", np.linalg.norm(sol-appsol)/np.linalg.norm(sol))\n"]},{"cell_type":"markdown","source":["## PCG Python implementation"],"metadata":{"id":"PeIbJFYE203U"}},{"cell_type":"code","source":["import numpy as np\n","\n","def apply_preconditioner(M, r):\n","    \"\"\"\n","    Apply a preconditioner matrix M to a vector r.\n","\n","    Parameters:\n","        M (numpy.ndarray): The preconditioner matrix.\n","        r (numpy.ndarray): The vector to be preconditioned.\n","\n","    Returns:\n","        z (numpy.ndarray): The preconditioned vector.\n","    \"\"\"\n","    # Apply the preconditioner by element-wise division\n","    z = r / np.diag(M)\n","    return z\n","\n","def pcg_cls(A, b, M, x0, tol=1e-6, max_iter=1000):\n","    \"\"\"\n","    Solve the linear system Ax = b using the preconditioned conjugate gradient method.\n","\n","    Parameters:\n","        A (numpy.ndarray): The coefficient matrix of the linear system.\n","        b (numpy.ndarray): The right-hand side vector.\n","        M (numpy.ndarray): The preconditioner matrix.\n","        x0 (numpy.ndarray): The initial guess for the solution.\n","        tol (float): The tolerance for convergence.\n","        max_iter (int): The maximum number of iterations allowed.\n","\n","    Returns:\n","        x (numpy.ndarray): The solution vector.\n","        num_iterations (int): The number of iterations performed.\n","    \"\"\"\n","    # Compute the initial residual\n","    r = b - np.dot(A, x0)\n","    # Apply the preconditioner to the initial residual\n","    z = apply_preconditioner(M, r)\n","    # Initialize the search direction\n","    p = z\n","    # Initialize the solution\n","    x = x0\n","    # Compute the norm of the initial residual\n","    r_norm_old = np.linalg.norm(r)\n","\n","    # Main iteration loop\n","    for k in range(max_iter):\n","        # Compute Ap\n","        Ap = np.dot(A, p)\n","        # Compute the step size\n","        alpha = np.dot(r, z) / np.dot(p, Ap)\n","        # Update the solution\n","        x = x + alpha * p\n","        # Update the residual\n","        r_new = r - alpha * Ap\n","        # Apply the preconditioner to the updated residual\n","        z_new = apply_preconditioner(M, r_new)\n","        # Compute the conjugate direction update factor\n","        beta = np.dot(r_new, z_new) / np.dot(r, z)\n","        # Update the search direction\n","        p = z_new + beta * p\n","        # Compute the norm of the updated residual\n","        r_norm_new = np.linalg.norm(r_new)\n","        # Check for convergence\n","        if r_norm_new < tol:\n","            break\n","        # Update the old residual and its preconditioned version for the next iteration\n","        r = r_new\n","        z = z_new\n","\n","    # Number of iterations performed\n","    num_iterations = k + 1\n","    return x, num_iterations\n","\n","# Example usage:\n","# Define the coefficient matrix A\n","A = np.array([[4, -1, 0], [-1, 4, -1], [0, -1, 3]])\n","# Define the right-hand side vector b\n","b = np.array([7, -4, 3])\n","# Initial guess for the solution\n","x0 = np.zeros_like(b)\n","# Example of a custom preconditioner matrix, for instance, the diagonal of A\n","M = np.diag(np.diag(A))\n","# Solve the linear system using preconditioned conjugate gradient method\n","solution, num_iterations = pcg_cls(A, b, M, x0)\n","# Print the solution and the number of iterations\n","print(\"PCG solution:\", solution)\n","print(\"Number of iterations:\", num_iterations)\n","x=np.linalg.solve(A,b)\n","print(\"Exact solution:\", x)\n","print(\"Solution relative error:\", np.linalg.norm(x-solution)/np.linalg.norm(x))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HXgnrue3uVAQ","executionInfo":{"status":"ok","timestamp":1713718535534,"user_tz":180,"elapsed":371,"user":{"displayName":"Luiz M. Carvalho","userId":"03500398417100793324"}},"outputId":"67eb127a-c7a7-4a72-8869-9de7a300c44b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PCG solution: [ 1.65853659 -0.36585366  0.87804878]\n","Number of iterations: 3\n","Exact solution: [ 1.65853659 -0.36585366  0.87804878]\n","Solution relative error: 1.19709221902474e-16\n"]}]},{"cell_type":"markdown","source":["## Essential property of Krylov subespace methods\n","\n"," *The **nontrivial nonlinearity is the main mathematical asset\n","as well as the beauty of Krylov subspace methods**, since it requires the\n","methods to adapt to the hidden inner structure of the problem to be solved.\n","This can lead to a significant speedup of the convergence in comparison\n","with (linear) iterative methods that do not adapt to the problem (p. 244).*"],"metadata":{"id":"lB5kcgNU_2Jl"}},{"cell_type":"markdown","source":["## The CG method\n","Here $A$ is symmetric positive definite.\n","\n","Combining (6) with (2)  results (*see the paper*) in the frequently stated convergence bound\n"," <a name=\"eq7\"></a>\n","$$\n","\\frac{||x-x_k||_A}{||x-x_0||_A}\\leqslant 2 \\begin{pmatrix} \\frac{\\sqrt{\\kappa(A)}-1}{\\sqrt{\\kappa(A)}+1}\\end{pmatrix}^k\\qquad (7)\n","$$\n","We will sometimes refer to (7) as the $\\kappa(A)$-bound. This bound implies that if the condition\n","number $\\kappa(A)$ is small, then a fast reduction of the $A$-norm of the error in the CG method\n","can be expected. **This bound does not imply, however, that a large condition number\n","results in slow convergence of CG**. In particular, preconditioners that provide smaller\n","condition numbers than others do not necessarily lead to faster convergence."],"metadata":{"id":"C49lQBQTQDG3"}},{"cell_type":"markdown","source":["## First example with diagonal matrix\n","\n","In the examples that follow, we will frequently make use of a certain class of diagonal\n","matrices which is often used in the literature to illuminate the behavior of CG. For a given $N\\geqslant 3,\\;$   $0<\\lambda_1<\\lambda_N,$ and $\\rho>0$ we define\n"," <a name=\"eq8\"></a>\n","$$\n","A=\\operatorname{diag}(\\lambda_1,\\lambda_2,\\dots,\\lambda_{N-1},\\lambda_{N}),\\text{ with } \\lambda_i=\\lambda_1+\\begin{pmatrix}\\frac{i-1}{N-1}\\end{pmatrix}(\\lambda_N-\\lambda_1)\\rho^{N-i}\\qquad (8)\n","$$\n","for $i=2,\\dots,N-1$. The parameter $\\rho$ determines the eigenvalue distribution of $A$. When\n","$\\rho = 1$, the eigenvalues are equally spaced between $\\lambda_1$ and $\\lambda_N$ . As $\\rho$ becomes smaller, the\n","eigenvalues accumulate towards $\\lambda_1$ ."],"metadata":{"id":"UwWsWtetWuzL"}},{"cell_type":"code","source":["import numpy as np\n","\n","def generate_diagonal_matrix_acc_left(rho, lambda_1, N, lambda_N):\n","    \"\"\"\n","    Generate a diagonal matrix A with the specified parameters.\n","\n","    Parameters:\n","        rho (float): The parameter rho.\n","        lambda_1 (float): The parameter lambda_1.\n","        N (int): The size of the matrix.\n","        lambda_N (float): The parameter lambda_N.\n","\n","    Returns:\n","        A (numpy.ndarray): The generated diagonal matrix.\n","    \"\"\"\n","    # Initialize the diagonal matrix with zeros\n","    A = np.zeros((N, N))\n","\n","    # Compute the diagonal elements according to the given formula\n","    for i in range(1, N+1):\n","        lambda_i = lambda_1 + ((i-1)/(N-1)) * (lambda_N - lambda_1) * rho**(N-i)\n","        A[i-1, i-1] = lambda_i\n","\n","    return A\n","\n","def generate_diagonal_matrix_acc_right(rho, lambda_1, N, lambda_N):\n","    \"\"\"\n","    Generate a diagonal matrix A with the specified parameters.\n","\n","    Parameters:\n","        rho (float): The parameter rho.\n","        lambda_1 (float): The parameter lambda_1.\n","        N (int): The size of the matrix.\n","        lambda_N (float): The parameter lambda_N.\n","\n","    Returns:\n","        A (numpy.ndarray): The generated diagonal matrix.\n","    \"\"\"\n","    # Initialize the diagonal matrix with zeros\n","    A = np.zeros((N, N))\n","\n","    # Compute the diagonal elements according to the given formula\n","    for i in range(1, N+1):\n","        lambda_i = lambda_N - ((i-1)/(N-1)) * (lambda_N - lambda_1) * rho**(N-i)\n","        A[i-1, i-1] = lambda_i\n","\n","    return A\n","\n","# Example usage:\n","rho = .5\n","lambda_1 = 1.0\n","lambda_N = 10.0\n","N = 5\n","A = generate_diagonal_matrix(rho, lambda_1, N, lambda_N)\n","print(\"Generated diagonal matrix A:\")\n","print(A)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MpU9jDYTfM1h","executionInfo":{"status":"ok","timestamp":1713715011205,"user_tz":180,"elapsed":17,"user":{"displayName":"Luiz M. Carvalho","userId":"03500398417100793324"}},"outputId":"dd7eb297-6253-4430-c8ba-a6bc03bceafa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated diagonal matrix A:\n","[[ 1.       0.       0.       0.       0.     ]\n"," [ 0.       1.28125  0.       0.       0.     ]\n"," [ 0.       0.       2.125    0.       0.     ]\n"," [ 0.       0.       0.       4.375    0.     ]\n"," [ 0.       0.       0.       0.      10.     ]]\n"]}]},{"cell_type":"markdown","source":["## Mathematical behavior of CG for diﬀerent eigenvalue distributions\n","\n","Let $x_0$ be the initial guess and $r_0=b-Ax_0$, the CG method constructs a uniquely\n","determined approximation\n","$$\n","x_k\\in x_0+\\mathcal{K}_k(A,r_0) \\text{ such that } r_k\\perp\\mathcal{K}_k(A,r_0)\\qquad (1)\n","$$\n","\n","Let $A=Q\\Lambda Q^T$, with $\\Lambda=\\operatorname{diag}(\\lambda_1,\\dots,\\lambda_N)$, and  $0<\\lambda_1\\leqslant\\cdots\\leqslant\\lambda_N$, be an orthogonal diagonalization of the matrix $A$,  \n","\n","We can represent the initial residual $r_0$ by its components in the\n","individual eigenvectors of $A$, stored in the columns of $Q$, as $r_0 = Q[\\eta_1 ,\\dots,\\eta_N ]^T$. The\n","approximation $x_k\\in x_0+\\mathcal{K}_k(A,r_0)$ that is uniquely determined by the orthogonality\n","condition in (1) satisﬁes the (equivalent) optimality property\n"," <a name=\"eq2\"></a>\n","$$\n","||x-x_k||_A=\\min_{p\\in P_k(0)}||p(A)(x-x_0)||_A=\\min_{p\\in P_k(0)}\\begin{pmatrix}\\displaystyle{\\sum_{i=1}^N \\eta_i^2\\frac{p(\\lambda_i)^2}{\\lambda_i}}\\end{pmatrix}^{1/2}\\qquad (2)\n","$$\n","### Main point\n","*The CG optimality property (see (2)) **depends on the positions of the\n","individual eigenvalues**. Therefore **CG adapts without any a priori information\n","not only to the spectral interval, but in a signiﬁcant (and nonlinear) way also\n","to the distribution of the inner eigenvalues**. Acceleration of CG convergence is\n","more pronounced for matrices with **outlying eigenvalues**, and is diﬀerent when\n","the outliers are small or large.*"],"metadata":{"id":"KzC98gkOh5gr"}},{"cell_type":"markdown","source":["### Setup\n","We consider the behavior of CG in exact arithmetic for matrices having three\n","diﬀerent eigenvalue distributions. All matrices are diagonal with $N = 30$, $\\lambda_1 = 0.1$, and $\\lambda_N=10^3$. The ﬁrst matrix is a slight modiﬁcation of [(8)](#eq8), $$\n","A=\\operatorname{diag}(\\lambda_1,\\lambda_2,\\dots,\\lambda_{N-1},\\lambda_{N}),\\text{ with } \\lambda_i=\\lambda_N-\\begin{pmatrix}\\frac{i-1}{N-1}\\end{pmatrix}(\\lambda_N-\\lambda_1)\\rho^{N-i}\n","$$\n","for $i=2,\\dots,N-1$, and $ \\rho= 0.6$, so that the eigenvalues accumulate on the\n","right side of the spectrum. The second matrix is (8) with $ \\rho= 0.6$, so that its eigenvalues\n","accumulate to the left side of the spectrum, and the third matrix is (8) with\n","$ \\rho= 0.6$,\n","so that its eigenvalues are equally spaced. In all cases we use $b = [1, . . . , 1]^T/ \\sqrt{N}$ , and\n","$x_0 = 0$."],"metadata":{"id":"JDKocnWSkkcj"}},{"cell_type":"markdown","source":["\n","\n","## References\n","\n"," - *Erin Carson, Jörg Liesen, Zdeněk Strakoš,* **Towards understanding CG and GMRES through\n","examples**,\n"," Linear Algebra and Its Applications, 2024 (https://doi.org/10.1016/j.laa.2024.04.003).  <a name=\"cls2024\"></a>\n","\n","\n"],"metadata":{"id":"ZS5zrSTQWJ7_"}},{"cell_type":"code","source":[],"metadata":{"id":"LsUrG7MxkXVK"},"execution_count":null,"outputs":[]}]}